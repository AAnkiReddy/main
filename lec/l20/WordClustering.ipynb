{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 579\n",
    "<br>\n",
    "\n",
    "## Clustering Words with K-Means\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Often, we want to know which features appear together.\n",
    "\n",
    "- If you liked *Twilight* you might like *Nosferatu*.\n",
    "- \"happy\" is a synonym of \"glad.\"\n",
    "\n",
    "Can be used to summarize a large collection of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use k-means to cluster together related words from Twitter.\n",
    "\n",
    "**Caution:** This uses live Twitter data, which often contains profanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Get some tweets containing the word 'i'.\n",
    "\n",
    "import os\n",
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "# Read Twitter credentials from environmental variables.\n",
    "api = TwitterAPI(os.environ.get('TW_CONSUMER_KEY'),\n",
    "                 os.environ.get('TW_CONSUMER_SECRET'),\n",
    "                 os.environ.get('TW_ACCESS_TOKEN'),\n",
    "                 os.environ.get('TW_ACCESS_TOKEN_SECRET'))\n",
    "\n",
    "# Collect 10000 tweets.\n",
    "tweets = []\n",
    "while True: \n",
    "    r = api.request('statuses/filter', {'track':'i',\n",
    "                                        'language':'en'})\n",
    "    if r.status_code != 200: # error\n",
    "        break\n",
    "    else:\n",
    "        for item in r.get_iterator():\n",
    "            tweets.append(item)\n",
    "            if len(tweets) > 10000:\n",
    "                break\n",
    "            elif len(tweets) % 100 == 0:\n",
    "                print(len(tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10002\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text RT @JARSMcLucien: Reposting @curvyphysique: ...\n",
      "\"The greatest feeling in the world is stepping out of your comfort zone. Taking a risk to oâ€¦\n",
      "description: None\n",
      "name: vrvrvr\n",
      "location: None\n"
     ]
    }
   ],
   "source": [
    "# Each tweet is a Python dict.\n",
    "print('text', tweets[0]['text'])\n",
    "print('description:', tweets[0]['user']['description'])\n",
    "print('name:', tweets[0]['user']['name'])\n",
    "print('location:', tweets[0]['user']['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = [t for t in tweets if 'text' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9234"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'reposting',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'feeling',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'is',\n",
       " 'stepping',\n",
       " 'out',\n",
       " 'of',\n",
       " 'your',\n",
       " 'comfort',\n",
       " 'zone',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'risk',\n",
       " 'to',\n",
       " 'o']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize each tweet text.\n",
    "import re\n",
    "tokens = []\n",
    "for tweet in tweets:\n",
    "    text = tweet['text'].lower()\n",
    "    text = re.sub('@\\S+', ' ', text)  # Remove mentions.\n",
    "    text = re.sub('http\\S+', ' ', text)  # Remove urls.\n",
    "    tokens.append(re.findall('[A-Za-z]+', text)) # Retain words.\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count words.\n",
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter()\n",
    "for tweet in tokens:\n",
    "    word_counts.update(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12214 unique terms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 11015),\n",
       " ('rt', 5101),\n",
       " ('the', 3586),\n",
       " ('to', 3556),\n",
       " ('a', 3012),\n",
       " ('you', 2457),\n",
       " ('and', 2273),\n",
       " ('m', 1934),\n",
       " ('my', 1925),\n",
       " ('it', 1811)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect word counts.\n",
    "import math\n",
    "\n",
    "print(len(word_counts), 'unique terms')\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3768 words occur at least three times.\n"
     ]
    }
   ],
   "source": [
    "# Retain in vocabulary words occurring more than twice.\n",
    "vocab = set([w for w, c in word_counts.items() if c > 2])\n",
    "print('%d words occur at least three times.' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prune tokens.\n",
    "newtoks = []\n",
    "for i, tweet in enumerate(tokens):\n",
    "    newtok = [token for token in tweet if token in vocab]\n",
    "    if len(newtok) > 0:\n",
    "        newtoks.append(newtok)\n",
    "tokens = newtoks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'feeling',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'is',\n",
       " 'out',\n",
       " 'of',\n",
       " 'your',\n",
       " 'comfort',\n",
       " 'zone',\n",
       " 'taking',\n",
       " 'a',\n",
       " 'risk',\n",
       " 'to',\n",
       " 'o']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A sample pruned tweet.\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context features**\n",
    "\n",
    "To determine if two words are similar, we will create a feature vector that counts how often other words appear nearby.\n",
    "\n",
    "E.g.,\n",
    "\n",
    "> I really **love** school.\n",
    "\n",
    "> I really **like** school.\n",
    "\n",
    "> You **love** school.\n",
    "\n",
    "**love:** {really@-1: 1, school@1: 1, you@-1: 1}\n",
    "\n",
    "**like:** {really@-1: 1, school@1: 1}\n",
    "\n",
    "<br>\n",
    "\n",
    "**Assumption**: words with similar meaning have similar contexts vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context for word feeling in ['rt', 'the', 'greatest', 'feeling', 'in', 'the', 'world', 'is', 'out', 'of', 'your', 'comfort', 'zone', 'taking', 'a', 'risk', 'to', 'o']\n",
      "['the@-2', 'greatest@-1', 'in@1', 'the@2']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_contexts(tweet, i, window):\n",
    "    \"\"\"\n",
    "    Get the context features for token at position i\n",
    "    in this tweet, using the given window size.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for j in range(np.amax([0, i-window]), i):\n",
    "        features.append(tweet[j] + \"@\" + str(j-i))\n",
    "    for j in range(i+1, min(i + window + 1, len(tweet))):\n",
    "        features.append(tweet[j] + \"@\" + str(j-i))\n",
    "    return features\n",
    "\n",
    "print('context for word %s in %s' % (tokens[0][3], tokens[0]))\n",
    "print(get_contexts(tokens[0], i=3, window=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q: How would the approach differ if we ignore location of context?**\n",
    "\n",
    "E.g., **love:** {really: 1, school:1, you: 1} **vs** {really@-1: 1, school@1: 1, you@-1: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For each term, create a context vector, indicating how often\n",
    "# each word occurs to the left or right of it.\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# dict from term to context vector.\n",
    "contexts = defaultdict(lambda: Counter())\n",
    "window = 2\n",
    "for tweet in tokens:\n",
    "    for i, token in enumerate(tweet):\n",
    "        features = get_contexts(tweet, i, window)\n",
    "        contexts[token].update(features)\n",
    "        # Optionally: ignore word order\n",
    "        # contexts[token].update(tweet[:i] + tweet[i+1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('m@1', 1885),\n",
       " ('rt@-1', 1631),\n",
       " ('t@2', 821),\n",
       " ('a@2', 519),\n",
       " ('rt@-2', 506),\n",
       " ('and@-1', 453),\n",
       " ('when@-1', 444),\n",
       " ('to@2', 399),\n",
       " ('don@1', 380),\n",
       " ('ve@1', 359),\n",
       " ('you@2', 358),\n",
       " ('love@1', 341),\n",
       " ('am@1', 338),\n",
       " ('can@1', 332),\n",
       " ('the@-2', 317),\n",
       " ('not@2', 310),\n",
       " ('but@-1', 302),\n",
       " ('just@1', 292),\n",
       " ('was@1', 258),\n",
       " ('have@1', 256)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts['i'].most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf-idf vectors**\n",
    "\n",
    "- We will transform the context features by dividing by (the log of) the number of distinct terms this feature appears in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i@-1', 10872),\n",
       " ('i@-2', 10470),\n",
       " ('i@1', 9138),\n",
       " ('i@2', 7095),\n",
       " ('rt@-1', 5081)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the number of different contexts each term appears in.\n",
    "tweet_freq = Counter()\n",
    "for context in contexts.values():\n",
    "    tweet_freq.update(context)\n",
    "tweet_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 241,\n",
       "         2: 732,\n",
       "         3: 3013,\n",
       "         4: 1956,\n",
       "         5: 1272,\n",
       "         6: 914,\n",
       "         7: 725,\n",
       "         8: 648,\n",
       "         9: 447,\n",
       "         10: 394,\n",
       "         11: 313,\n",
       "         12: 290,\n",
       "         13: 235,\n",
       "         14: 184,\n",
       "         15: 163,\n",
       "         16: 165,\n",
       "         17: 103,\n",
       "         18: 145,\n",
       "         19: 138,\n",
       "         20: 104,\n",
       "         21: 76,\n",
       "         22: 89,\n",
       "         23: 86,\n",
       "         24: 72,\n",
       "         25: 81,\n",
       "         26: 77,\n",
       "         27: 62,\n",
       "         28: 57,\n",
       "         29: 63,\n",
       "         30: 53,\n",
       "         31: 51,\n",
       "         32: 36,\n",
       "         33: 41,\n",
       "         34: 39,\n",
       "         35: 51,\n",
       "         36: 33,\n",
       "         37: 21,\n",
       "         38: 41,\n",
       "         39: 39,\n",
       "         40: 28,\n",
       "         41: 47,\n",
       "         42: 32,\n",
       "         43: 38,\n",
       "         44: 29,\n",
       "         45: 29,\n",
       "         46: 32,\n",
       "         47: 35,\n",
       "         48: 24,\n",
       "         49: 20,\n",
       "         50: 24,\n",
       "         51: 14,\n",
       "         52: 14,\n",
       "         53: 22,\n",
       "         54: 24,\n",
       "         55: 17,\n",
       "         56: 24,\n",
       "         57: 21,\n",
       "         58: 23,\n",
       "         59: 21,\n",
       "         60: 21,\n",
       "         61: 12,\n",
       "         62: 10,\n",
       "         63: 17,\n",
       "         64: 9,\n",
       "         65: 13,\n",
       "         66: 12,\n",
       "         67: 17,\n",
       "         68: 15,\n",
       "         69: 8,\n",
       "         70: 11,\n",
       "         71: 7,\n",
       "         72: 9,\n",
       "         73: 5,\n",
       "         74: 14,\n",
       "         75: 9,\n",
       "         76: 12,\n",
       "         77: 13,\n",
       "         78: 8,\n",
       "         79: 18,\n",
       "         80: 11,\n",
       "         81: 11,\n",
       "         82: 13,\n",
       "         83: 7,\n",
       "         84: 12,\n",
       "         85: 8,\n",
       "         86: 6,\n",
       "         87: 8,\n",
       "         88: 8,\n",
       "         89: 8,\n",
       "         90: 6,\n",
       "         91: 6,\n",
       "         92: 8,\n",
       "         93: 12,\n",
       "         94: 5,\n",
       "         95: 6,\n",
       "         96: 10,\n",
       "         97: 6,\n",
       "         98: 5,\n",
       "         99: 9,\n",
       "         100: 5,\n",
       "         101: 5,\n",
       "         102: 5,\n",
       "         103: 3,\n",
       "         104: 7,\n",
       "         105: 11,\n",
       "         106: 15,\n",
       "         107: 7,\n",
       "         108: 6,\n",
       "         109: 9,\n",
       "         110: 4,\n",
       "         111: 9,\n",
       "         112: 4,\n",
       "         113: 8,\n",
       "         114: 9,\n",
       "         115: 6,\n",
       "         116: 3,\n",
       "         117: 2,\n",
       "         118: 4,\n",
       "         119: 3,\n",
       "         120: 3,\n",
       "         121: 2,\n",
       "         123: 3,\n",
       "         124: 4,\n",
       "         125: 4,\n",
       "         126: 4,\n",
       "         127: 2,\n",
       "         128: 2,\n",
       "         129: 9,\n",
       "         130: 4,\n",
       "         131: 8,\n",
       "         132: 1,\n",
       "         133: 7,\n",
       "         134: 4,\n",
       "         135: 2,\n",
       "         136: 6,\n",
       "         137: 8,\n",
       "         138: 5,\n",
       "         139: 2,\n",
       "         140: 1,\n",
       "         141: 4,\n",
       "         142: 1,\n",
       "         143: 2,\n",
       "         144: 2,\n",
       "         145: 3,\n",
       "         146: 4,\n",
       "         147: 3,\n",
       "         148: 2,\n",
       "         150: 3,\n",
       "         151: 3,\n",
       "         152: 1,\n",
       "         153: 3,\n",
       "         154: 2,\n",
       "         155: 4,\n",
       "         156: 2,\n",
       "         157: 2,\n",
       "         158: 3,\n",
       "         159: 1,\n",
       "         160: 2,\n",
       "         161: 1,\n",
       "         162: 1,\n",
       "         164: 1,\n",
       "         165: 3,\n",
       "         166: 1,\n",
       "         167: 2,\n",
       "         168: 2,\n",
       "         169: 3,\n",
       "         170: 1,\n",
       "         171: 2,\n",
       "         172: 2,\n",
       "         173: 3,\n",
       "         174: 2,\n",
       "         176: 4,\n",
       "         177: 2,\n",
       "         179: 1,\n",
       "         180: 3,\n",
       "         181: 2,\n",
       "         182: 1,\n",
       "         183: 1,\n",
       "         184: 5,\n",
       "         185: 4,\n",
       "         186: 2,\n",
       "         187: 2,\n",
       "         188: 1,\n",
       "         189: 4,\n",
       "         190: 1,\n",
       "         191: 1,\n",
       "         193: 1,\n",
       "         194: 1,\n",
       "         195: 1,\n",
       "         196: 2,\n",
       "         197: 1,\n",
       "         198: 6,\n",
       "         200: 5,\n",
       "         201: 2,\n",
       "         202: 2,\n",
       "         203: 4,\n",
       "         204: 1,\n",
       "         205: 3,\n",
       "         206: 2,\n",
       "         207: 3,\n",
       "         209: 1,\n",
       "         210: 1,\n",
       "         213: 2,\n",
       "         214: 1,\n",
       "         215: 1,\n",
       "         216: 2,\n",
       "         217: 2,\n",
       "         220: 2,\n",
       "         221: 4,\n",
       "         222: 1,\n",
       "         225: 2,\n",
       "         226: 1,\n",
       "         228: 1,\n",
       "         231: 1,\n",
       "         232: 1,\n",
       "         233: 3,\n",
       "         235: 1,\n",
       "         236: 2,\n",
       "         237: 1,\n",
       "         238: 1,\n",
       "         239: 1,\n",
       "         240: 4,\n",
       "         241: 2,\n",
       "         242: 1,\n",
       "         243: 3,\n",
       "         245: 2,\n",
       "         246: 1,\n",
       "         247: 3,\n",
       "         250: 2,\n",
       "         251: 2,\n",
       "         252: 2,\n",
       "         254: 1,\n",
       "         255: 4,\n",
       "         256: 1,\n",
       "         257: 1,\n",
       "         258: 3,\n",
       "         260: 1,\n",
       "         261: 1,\n",
       "         262: 1,\n",
       "         263: 3,\n",
       "         266: 2,\n",
       "         267: 3,\n",
       "         268: 1,\n",
       "         269: 2,\n",
       "         270: 2,\n",
       "         272: 1,\n",
       "         273: 2,\n",
       "         274: 1,\n",
       "         276: 3,\n",
       "         278: 1,\n",
       "         279: 2,\n",
       "         280: 1,\n",
       "         281: 1,\n",
       "         282: 1,\n",
       "         283: 1,\n",
       "         284: 1,\n",
       "         286: 1,\n",
       "         289: 2,\n",
       "         293: 1,\n",
       "         294: 1,\n",
       "         295: 2,\n",
       "         296: 1,\n",
       "         298: 1,\n",
       "         301: 1,\n",
       "         302: 2,\n",
       "         303: 1,\n",
       "         305: 1,\n",
       "         306: 1,\n",
       "         307: 1,\n",
       "         308: 2,\n",
       "         310: 1,\n",
       "         312: 1,\n",
       "         313: 1,\n",
       "         315: 2,\n",
       "         316: 1,\n",
       "         317: 1,\n",
       "         319: 1,\n",
       "         320: 2,\n",
       "         321: 1,\n",
       "         323: 1,\n",
       "         324: 1,\n",
       "         327: 1,\n",
       "         329: 2,\n",
       "         330: 1,\n",
       "         334: 1,\n",
       "         336: 1,\n",
       "         338: 1,\n",
       "         340: 1,\n",
       "         341: 1,\n",
       "         342: 2,\n",
       "         343: 1,\n",
       "         344: 1,\n",
       "         346: 1,\n",
       "         348: 1,\n",
       "         350: 1,\n",
       "         351: 1,\n",
       "         353: 3,\n",
       "         354: 1,\n",
       "         356: 1,\n",
       "         361: 2,\n",
       "         369: 1,\n",
       "         374: 1,\n",
       "         375: 1,\n",
       "         381: 3,\n",
       "         383: 1,\n",
       "         384: 1,\n",
       "         387: 1,\n",
       "         388: 1,\n",
       "         393: 1,\n",
       "         399: 1,\n",
       "         401: 1,\n",
       "         404: 2,\n",
       "         406: 1,\n",
       "         408: 1,\n",
       "         411: 2,\n",
       "         414: 1,\n",
       "         419: 1,\n",
       "         422: 1,\n",
       "         423: 2,\n",
       "         426: 1,\n",
       "         427: 1,\n",
       "         428: 1,\n",
       "         431: 1,\n",
       "         432: 2,\n",
       "         433: 2,\n",
       "         434: 2,\n",
       "         437: 2,\n",
       "         440: 1,\n",
       "         445: 1,\n",
       "         446: 1,\n",
       "         447: 2,\n",
       "         450: 2,\n",
       "         453: 1,\n",
       "         459: 1,\n",
       "         465: 1,\n",
       "         471: 1,\n",
       "         474: 1,\n",
       "         477: 1,\n",
       "         481: 1,\n",
       "         485: 1,\n",
       "         493: 1,\n",
       "         504: 1,\n",
       "         506: 1,\n",
       "         510: 1,\n",
       "         516: 1,\n",
       "         520: 1,\n",
       "         548: 1,\n",
       "         565: 1,\n",
       "         566: 1,\n",
       "         570: 1,\n",
       "         571: 1,\n",
       "         573: 1,\n",
       "         577: 1,\n",
       "         578: 1,\n",
       "         580: 1,\n",
       "         589: 2,\n",
       "         590: 1,\n",
       "         591: 1,\n",
       "         607: 1,\n",
       "         613: 1,\n",
       "         634: 1,\n",
       "         637: 1,\n",
       "         639: 1,\n",
       "         640: 1,\n",
       "         643: 1,\n",
       "         646: 2,\n",
       "         651: 1,\n",
       "         652: 1,\n",
       "         654: 1,\n",
       "         671: 2,\n",
       "         672: 1,\n",
       "         673: 1,\n",
       "         677: 1,\n",
       "         678: 1,\n",
       "         681: 1,\n",
       "         682: 1,\n",
       "         686: 1,\n",
       "         692: 3,\n",
       "         693: 1,\n",
       "         700: 2,\n",
       "         701: 1,\n",
       "         710: 1,\n",
       "         711: 1,\n",
       "         717: 1,\n",
       "         718: 1,\n",
       "         723: 1,\n",
       "         725: 1,\n",
       "         730: 1,\n",
       "         733: 1,\n",
       "         738: 1,\n",
       "         745: 2,\n",
       "         750: 1,\n",
       "         786: 1,\n",
       "         793: 1,\n",
       "         795: 1,\n",
       "         802: 1,\n",
       "         805: 1,\n",
       "         813: 1,\n",
       "         827: 1,\n",
       "         907: 1,\n",
       "         909: 1,\n",
       "         910: 1,\n",
       "         935: 1,\n",
       "         942: 1,\n",
       "         951: 1,\n",
       "         1001: 1,\n",
       "         1048: 1,\n",
       "         1077: 1,\n",
       "         1101: 1,\n",
       "         1115: 1,\n",
       "         1117: 1,\n",
       "         1125: 1,\n",
       "         1154: 1,\n",
       "         1157: 1,\n",
       "         1166: 1,\n",
       "         1177: 1,\n",
       "         1198: 1,\n",
       "         1207: 1,\n",
       "         1212: 1,\n",
       "         1218: 1,\n",
       "         1244: 1,\n",
       "         1255: 1,\n",
       "         1260: 1,\n",
       "         1262: 1,\n",
       "         1272: 1,\n",
       "         1284: 1,\n",
       "         1290: 1,\n",
       "         1299: 1,\n",
       "         1316: 1,\n",
       "         1359: 1,\n",
       "         1385: 1,\n",
       "         1391: 1,\n",
       "         1395: 1,\n",
       "         1418: 1,\n",
       "         1430: 1,\n",
       "         1492: 1,\n",
       "         1493: 1,\n",
       "         1532: 1,\n",
       "         1534: 1,\n",
       "         1559: 1,\n",
       "         1563: 1,\n",
       "         1570: 1,\n",
       "         1571: 1,\n",
       "         1601: 1,\n",
       "         1639: 1,\n",
       "         1653: 1,\n",
       "         1658: 1,\n",
       "         1671: 1,\n",
       "         1711: 1,\n",
       "         1729: 1,\n",
       "         1749: 2,\n",
       "         1778: 1,\n",
       "         1851: 1,\n",
       "         1875: 1,\n",
       "         1877: 1,\n",
       "         1933: 1,\n",
       "         2064: 1,\n",
       "         2122: 1,\n",
       "         2156: 1,\n",
       "         2202: 1,\n",
       "         2213: 1,\n",
       "         2234: 1,\n",
       "         2268: 1,\n",
       "         2403: 1,\n",
       "         2630: 1,\n",
       "         2900: 1,\n",
       "         2932: 1,\n",
       "         2993: 1,\n",
       "         3130: 1,\n",
       "         3150: 1,\n",
       "         3357: 1,\n",
       "         3446: 1,\n",
       "         3472: 1,\n",
       "         3504: 1,\n",
       "         3527: 1,\n",
       "         3548: 1,\n",
       "         5064: 1,\n",
       "         5081: 1,\n",
       "         7095: 1,\n",
       "         9138: 1,\n",
       "         10470: 1,\n",
       "         10872: 1})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tweet_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('m@1', 0.5582214597504179),\n",
       " ('rt@-1', 0.4340378615319769),\n",
       " ('t@2', 0.2460022777183741),\n",
       " ('when@-1', 0.1478219992761952),\n",
       " ('a@2', 0.1465682588130064)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform each context vector to be term freq / tweet frequency. \n",
    "# Also then normalize by length.\n",
    "for term, context in contexts.items():\n",
    "    for term2, frequency in context.items():\n",
    "        context[term2] = frequency / (1. + math.log(tweet_freq[term2]))\n",
    "    length = math.sqrt(sum([v*v for v in context.values()]))\n",
    "    for term2, frequency in context.items():\n",
    "        context[term2] = 1. * frequency / length\n",
    "    \n",
    "contexts['i'].most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('high@-1', 0.44824461523385556),\n",
       " ('middle@-1', 0.276809786508761),\n",
       " ('dance@1', 0.22496667376105228),\n",
       " ('in@-2', 0.22153077383442005),\n",
       " ('at@-1', 0.20311253102482868),\n",
       " ('i@1', 0.19779675303454353),\n",
       " ('haven@2', 0.18237836627142215),\n",
       " ('med@-1', 0.18197655195331622),\n",
       " ('to@-1', 0.17909179275324286),\n",
       " ('to@-2', 0.16088479142291645)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts['school'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i@-1', 0.8137148135270944),\n",
       " ('you@1', 0.3719081059401668),\n",
       " ('rt@-2', 0.1778524815448788),\n",
       " ('in@-1', 0.10348512628664915),\n",
       " ('so@2', 0.10184880113176296),\n",
       " ('i@-2', 0.0981960838507083),\n",
       " ('u@1', 0.08830235442789779),\n",
       " ('babies@2', 0.07162307293925912),\n",
       " ('to@1', 0.06961578792104153),\n",
       " ('this@1', 0.06904772892089626)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts['love'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i@-1', 0.7914599480479385),\n",
       " ('rt@-2', 0.31577868748481397),\n",
       " ('when@1', 0.14534233096643914),\n",
       " ('prejudices@-2', 0.14064065606799675),\n",
       " ('suspicious@2', 0.12303362601123709),\n",
       " ('seeing@1', 0.11587545481482033),\n",
       " ('received@-1', 0.10530929429508859),\n",
       " ('it@1', 0.10402789702708894),\n",
       " ('due@1', 0.09897197720363868),\n",
       " ('country@1', 0.09249593826492027)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts['hate'].most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have a list of dictionaries, one per term, indicating the terms that co-occur (weighted by inverse tweet frequency).\n",
    "\n",
    "Next, we have to cluster these vectors. To do this, we'll need to be able to compute the euclidean distance between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "# n.b. This is not efficient!\n",
    "def distance(c1, c2):\n",
    "    if len(c1.keys()) == 0 or len(c2.keys()) == 0:\n",
    "        return 1e9\n",
    "    keys = set(c1.keys()) | set(c2.keys())\n",
    "    distance = 0.\n",
    "    for k in keys:\n",
    "        distance += (c1[k] - c2[k]) ** 2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "print(distance({'hi':10, 'bye': 5}, {'hi': 9, 'bye': 4}))\n",
    "print(distance({'hi':10, 'bye': 5}, {'hi': 8, 'bye': 4}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['love', 'hope', 'miss', 'm', 'hate', 'am', 'll', 'swear', 'think',\n",
       "       'thought'],\n",
       "      dtype='<U76')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_closest(term, n=5):\n",
    "    terms = np.array(list(contexts.keys()))\n",
    "    context = contexts[term]\n",
    "    distances = []\n",
    "    for term2, context2 in contexts.items():\n",
    "        distances.append(distance(context, context2))\n",
    "    return terms[np.argsort(distances)][:n]\n",
    "\n",
    "find_closest('love', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3768 nonzero contexts\n"
     ]
    }
   ],
   "source": [
    "nz_contexts = [t for t, context in contexts.items()\n",
    "               if len(context) > 1]\n",
    "contexts = dict([(term, contexts[term]) for term in nz_contexts])\n",
    "print(len(nz_contexts), 'nonzero contexts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt\n",
      "[('the@1', 0.0683073756730184), ('greatest@2', 0.002745818714779079), ('when@1', 0.04446290612775616)]\n"
     ]
    }
   ],
   "source": [
    "# e.g., what are three context features for the term \"rt\"?\n",
    "print(list(contexts.keys())[0])\n",
    "print(list(list(contexts.values())[0].items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a@-1' 'a@-2' 'a@1' 'a@2' 'abandoned@-1' 'abandoned@-2' 'abandoned@1'\n",
      " 'abandoned@2' 'able@-1' 'able@-2']\n",
      "  (0, 0)\t0.00469227029408\n",
      "  (0, 1)\t0.00237197032823\n",
      "  (0, 2)\t0.0192877598577\n",
      "  (0, 3)\t0.0240185086907\n",
      "  (0, 11)\t0.00133419593933\n",
      "  (0, 16)\t0.00148857295274\n",
      "  (0, 17)\t0.00149201211056\n",
      "  (0, 30)\t0.00270547638962\n",
      "  (0, 31)\t0.00147622138247\n",
      "  (0, 111)\t0.00125959470189\n",
      "  (0, 115)\t0.00117845179014\n",
      "  (0, 146)\t0.000929232994559\n",
      "  (0, 147)\t0.000933967628242\n",
      "  (0, 163)\t0.00144615871426\n",
      "  (0, 179)\t0.00250768305196\n",
      "  (0, 183)\t0.00159349549542\n",
      "  (0, 195)\t0.0034179278273\n",
      "  (0, 219)\t0.00141925113834\n",
      "  (0, 248)\t0.00731738520698\n",
      "  (0, 249)\t0.00651553583701\n",
      "  (0, 253)\t0.00285362485145\n",
      "  (0, 281)\t0.00561184662607\n",
      "  (0, 285)\t0.00377878410568\n",
      "  (0, 304)\t0.00250768305196\n",
      "  (0, 316)\t0.000884664125953\n",
      "  :\t:\n",
      "  (0, 14753)\t0.00272794573339\n",
      "  (0, 14754)\t0.013761695615\n",
      "  (0, 14757)\t0.00187117507715\n",
      "  (0, 14758)\t0.0131681115934\n",
      "  (0, 14766)\t0.00188506729428\n",
      "  (0, 14773)\t0.00358719730966\n",
      "  (0, 14774)\t0.00251918940378\n",
      "  (0, 14777)\t0.00234077421064\n",
      "  (0, 14778)\t0.00118688986373\n",
      "  (0, 14782)\t0.00111648965889\n",
      "  (0, 14785)\t0.00220001917634\n",
      "  (0, 14790)\t0.00151012781626\n",
      "  (0, 14794)\t0.0044107336921\n",
      "  (0, 14798)\t0.00658402854304\n",
      "  (0, 14799)\t0.00120611053699\n",
      "  (0, 14801)\t0.0664985401372\n",
      "  (0, 14802)\t0.051404305485\n",
      "  (0, 14805)\t0.00128638471219\n",
      "  (0, 14806)\t0.00260236136649\n",
      "  (0, 14813)\t0.00225179885662\n",
      "  (0, 14814)\t0.00978193957847\n",
      "  (0, 14826)\t0.00121477516968\n",
      "  (0, 14832)\t0.00501536610392\n",
      "  (0, 14844)\t0.00526265446893\n",
      "  (0, 14864)\t0.0318515391669\n"
     ]
    }
   ],
   "source": [
    "# Transform context dicts to a sparse vector\n",
    "# for sklearn.\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X = vec.fit_transform(contexts.values())\n",
    "names = np.array(vec.get_feature_names())\n",
    "print(names[:10])\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "  (0, 1)\t0.00553572015238\n",
      "  (0, 2)\t0.0109124611968\n",
      "  (0, 3)\t0.0136718428235\n",
      "  (0, 14)\t0.00348673067176\n",
      "  (0, 15)\t0.00353406694781\n",
      "  (0, 17)\t0.00348206780233\n",
      "  (0, 28)\t0.00614756806249\n",
      "  (0, 144)\t0.00434457169663\n",
      "  (0, 145)\t0.00454324239669\n",
      "  (0, 245)\t0.00797678273112\n",
      "  (0, 250)\t0.00487086781525\n",
      "  (0, 295)\t0.0076829248359\n",
      "  (0, 324)\t0.00722919164337\n",
      "  (0, 327)\t0.00722919164337\n",
      "  (0, 341)\t0.00562454137925\n",
      "  (0, 351)\t0.00659255897575\n",
      "  (0, 352)\t0.022868052213\n",
      "  (0, 353)\t0.0197527099471\n",
      "  (0, 375)\t0.00587930101157\n",
      "  (0, 401)\t0.00453307965468\n",
      "  (0, 410)\t0.00838389846504\n",
      "  (0, 411)\t0.00426934058479\n",
      "  (0, 413)\t0.00851338713158\n",
      "  (0, 423)\t0.0116448253662\n",
      "  (0, 456)\t0.00361445370419\n",
      "  :\t:\n",
      "  (0, 14561)\t0.00857774499953\n",
      "  (0, 14567)\t0.00640821000721\n",
      "  (0, 14599)\t0.0083404346929\n",
      "  (0, 14606)\t0.00571810263689\n",
      "  (0, 14643)\t0.00797678273112\n",
      "  (0, 14649)\t0.00689043059188\n",
      "  (0, 14651)\t0.00651118844902\n",
      "  (0, 14652)\t0.0307138624097\n",
      "  (0, 14669)\t0.010042902075\n",
      "  (0, 14689)\t0.00558121665107\n",
      "  (0, 14697)\t0.00631405882004\n",
      "  (0, 14707)\t0.00526722663386\n",
      "  (0, 14718)\t0.00389394320112\n",
      "  (0, 14744)\t0.00689043059188\n",
      "  (0, 14748)\t0.00535920903589\n",
      "  (0, 14771)\t0.00500079826255\n",
      "  (0, 14785)\t0.00513441940867\n",
      "  (0, 14799)\t0.0365927744711\n",
      "  (0, 14800)\t0.0510562140066\n",
      "  (0, 14801)\t0.37190810594\n",
      "  (0, 14802)\t0.0282276966022\n",
      "  (0, 14811)\t0.00702938094687\n",
      "  (0, 14813)\t0.0245245614667\n",
      "  (0, 14814)\t0.0105365334224\n",
      "  (0, 14831)\t0.0117048948221\n",
      "yea@-1\n"
     ]
    }
   ],
   "source": [
    "# Which row of X is the word \"love\"?\n",
    "love_idx = list(contexts.keys()).index('love')\n",
    "print(love_idx)\n",
    "# What are the context feature values for love?\n",
    "print(X[love_idx])\n",
    "# Print a highly ranking feature.\n",
    "print(names[14743])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=20, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's cluster!\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 20\n",
    "kmeans = KMeans(num_clusters)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 s@-1 it@-2 i@-2 i@1 and@1\n",
      "1 of@1 the@-1 a@-1 the@2 the@-2\n",
      "2 to@-1 i@-1 i@-2 t@-1 i@2\n",
      "3 the@-1 i@2 in@-2 i@1 of@-2\n",
      "4 i@1 rt@-1 m@2 i@2 i@-2\n",
      "5 my@-1 i@1 and@1 i@2 your@-1\n",
      "6 t@1 i@-1 we@-1 if@-2 heart@-2\n",
      "7 to@1 i@-2 i@-1 m@-1 the@2\n",
      "8 of@-1 the@-1 and@1 the@-2 i@1\n",
      "9 my@-2 i@1 i@2 and@1 the@-1\n",
      "10 m@-2 i@2 so@-1 when@1 i@1\n",
      "11 i@-1 rt@-2 i@-2 the@1 you@1\n",
      "12 and@1 i@2 i@1 i@-2 the@-1\n",
      "13 be@-1 to@-2 the@2 in@1 i@-2\n",
      "14 on@1 the@2 i@-2 i@1 i@2\n",
      "15 a@-1 i@1 i@2 the@-1 is@-2\n",
      "16 i@-2 rt@-1 the@-2 the@-1 and@-1\n",
      "17 i@-2 m@-1 i@2 i@1 the@1\n",
      "18 this@-1 i@1 the@-1 a@-1 i@2\n",
      "19 a@-2 a@-1 the@-1 i@2 the@-2\n"
     ]
    }
   ],
   "source": [
    "# Let's print out the top features for each mean vector.\n",
    "# This is swamped by common terms\n",
    "for i in range(num_clusters):\n",
    "    print(i, ' '.join(names[np.argsort(\n",
    "        kmeans.cluster_centers_[i])[::-1][:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance from term \"love\" to each cluster:\n",
      "[ 0.99906709  1.03256762  0.93987811  1.024899    1.01064838  1.01944766\n",
      "  1.10228092  0.98968205  0.99938276  0.98827777  0.97608548  0.62476626\n",
      "  0.98192206  1.00981618  1.0011895   1.03278746  0.97250793  0.98842098\n",
      "  1.01922596  0.99833337]\n",
      "closest cluster to \"love\":\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# .transform will compute the distance from each context to each cluster.\n",
    "distances = kmeans.transform(X)\n",
    "# e.g., what is the distance from the word \"love\" to each cluster?\n",
    "print('distance from term \"love\" to each cluster:')\n",
    "print(distances[love_idx])\n",
    "# what is the closest cluster for the word \"love\"?\n",
    "print('closest cluster to \"love\":')\n",
    "print(np.argmin(distances[love_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 funny gavin quavos som bright totally gooooooo dealing parents \n",
      "\n",
      "1 amount kind proud one part instead president tired colour \n",
      "\n",
      "2 do see say begin watch find take get read \n",
      "\n",
      "3 best truth past world shows stars club gist way \n",
      "\n",
      "4 and when what but yes hi today if wow \n",
      "\n",
      "5 mom own heart brother bestfriend cousins favorite mind hair \n",
      "\n",
      "6 didn wouldn couldn wasn doesn ain haven won isn \n",
      "\n",
      "7 used supposed wanted listening want decided listen willing starting \n",
      "\n",
      "8 them africa yours the peo society pruitt meat heaven \n",
      "\n",
      "9 but rt time where priority today thing what now \n",
      "\n",
      "10 jealous excited the bored much but and annoyed for \n",
      "\n",
      "11 am love ll hate hope swear think just saw \n",
      "\n",
      "12 plans cousins oppression apologize complex me thoughts strong corner \n",
      "\n",
      "13 dramatic amazed careful motivated honest perfect embarrassed ashamed successful \n",
      "\n",
      "14 working out shame congrats focus blast popular jump cheating \n",
      "\n",
      "15 great few bit couple star bl playlist believer video \n",
      "\n",
      "16 and you the that my me do for a \n",
      "\n",
      "17 honored sorry nervous done gonna so bored a odie \n",
      "\n",
      "18 is tweet morning piece month year guy thread opportunity \n",
      "\n",
      "19 top excuse supporter of man day relationship where person \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally, we'll print the words that are closest\n",
    "# to the mean of each cluster.\n",
    "terms = np.array(list(contexts.keys()))\n",
    "for i in range(distances.shape[1]):\n",
    "    print(i, ' '.join(terms[np.argsort(distances[:,i])[1:10]]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, interpreting these results requires a bit of investigation.\n",
    "\n",
    "As the number of tweets increases, we expect these clusters to become more coherent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does error decrease with number of cluster?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3448.3248338538415"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.score(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5 score=3568.43\n",
      "k=10 score=3501.97\n",
      "k=20 score=3448.02\n",
      "k=50 score=3365.94\n",
      "k=100 score=3288.19\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ee1668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "scores = []\n",
    "num_cluster_options = [5,10,20,50,100]\n",
    "\n",
    "for num_clusters in num_cluster_options:\n",
    "    kmeans = KMeans(num_clusters, n_init=10, max_iter=10)\n",
    "    kmeans.fit(X)\n",
    "    score = -1 * kmeans.score(X)\n",
    "    scores.append(score)\n",
    "    print('k=%d score=%g' % (num_clusters, score))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(num_cluster_options, scores, 'bo-')\n",
    "plt.xlabel('num clusters')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** How does error vary by initalization? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=3456.04\n",
      "score=3455.95\n",
      "score=3457.99\n",
      "score=3461.53\n",
      "score=3459.64\n",
      "score=3461.99\n",
      "score=3461.05\n",
      "score=3457.85\n",
      "score=3463.08\n",
      "score=3457.6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzFrEicPMzFrEicPMzFrk/wOCS4k6lXW8iQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ca5a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(10):\n",
    "    kmeans = KMeans(20, n_init=1,\n",
    "                    max_iter=100,\n",
    "                    init='random')\n",
    "    kmeans.fit(X)\n",
    "    score = -1 * kmeans.score(X)\n",
    "    scores.append(score)\n",
    "    print('score=%g' % (score))\n",
    "     \n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(range(10), sorted(scores), 'bo-')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
